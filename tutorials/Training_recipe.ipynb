{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e28211e",
   "metadata": {},
   "source": [
    "# Training Recipe\n",
    "\n",
    "Source: [Link](https://docs.nvidia.com/physicsnemo/latest/user-guide/simple_training_example.html)\n",
    "\n",
    "In this tutorial, you will learn how to use utilities from PhysicsNeMo to set up a model training pipeline. After completing the initial setup, you will explore optimizing the training loop and running it in a distributed fashion. You will finish the tutorial with an inference workflow that demonstrates how to use PhysicsNeMo models for inference.\n",
    "\n",
    "## Basic Training Workflow\n",
    "\n",
    "Let’s get started. For the purposes of this tutorial, we will focus more on the PhysicsNeMo utilities and not the correctness of the problem definition or the results. A typical training workflow requires data, a trainable model, and an optimizer to update the model parameters.\n",
    "\n",
    "### Using Built-in Models\n",
    "\n",
    "In this example, you will explore different ways to interact with models in PhysicsNeMo. PhysicsNeMo provides a library of models suitable for Physics-ML applications that you can use directly in your training workflows. In this tutorial, you will see how to use a model in PhysicsNeMo to set up data-driven training. Using the models from PhysicsNeMo enables you to access various other PhysicsNeMo features like optimization and quality-of-life functionalities such as checkpointing and model entrypoints.\n",
    "\n",
    "Later, you will also see how to customize these models in PhysicsNeMo.\n",
    "\n",
    "In this example, you will use the Fourier Neural Operator (FNO) model from PhysicsNeMo. To demonstrate the training using this model, you need some dataset to train the model. To allow for fast prototyping of models, PhysicsNeMo provides a set of benchmark datasets that you can use out of the box without the need to set up data-loading pipelines. In this example, you will use one such datapipe called Darcy2D, which is a 2D Darcy problem with a random permeability field. For more information on the FNO model or 2D-Darcy problem, refer to [Li et al., 2020](https://arxiv.org/abs/2010.08895)\n",
    "\n",
    "Let’s start by importing a few utilities and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import physicsnemo\n",
    "from physicsnemo.datapipes.benchmarks.darcy import Darcy2D\n",
    "from physicsnemo.metrics.general.mse import mse\n",
    "from physicsnemo.models.fno.fno import FNO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3785a",
   "metadata": {},
   "source": [
    "In this example, you want to develop a mapping between the permeability and its subsequent pressure field for a given forcing function. Refer to [PhysicsNeMo DataPipes](https://docs.nvidia.com/physicsnemo/latest/physicsnemo/examples/minimal/datapipes/README.html#physicsnemo-datapipes) for additional details.\n",
    "\n",
    "Then, a training loop for this example can be written as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normaliser = { # Dictionary with mean and std of the permeability and darcy fields\n",
    "    \"permeability\": (1.25, 0.75), \n",
    "    \"darcy\": (4.52e-2, 2.79e-2),\n",
    "}\n",
    "dataloader = Darcy2D(\n",
    "    resolution=256, batch_size=64, nr_permeability_freq=5, normaliser=normaliser\n",
    ")\n",
    "model = FNO(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    decoder_layers=1,\n",
    "    decoder_layer_size=32,\n",
    "    dimension=2,\n",
    "    latent_channels=32,\n",
    "    num_fno_layers=4,\n",
    "    num_fno_modes=12,\n",
    "    padding=5,\n",
    ").to(\"cuda\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer, lr_lambda=lambda step: 0.85**step\n",
    ")\n",
    "\n",
    "# run for 20 iterations\n",
    "dataloader = iter(dataloader)\n",
    "for i in range(20):\n",
    "    batch = next(dataloader)\n",
    "    truth = batch[\"darcy\"]\n",
    "    pred = model(batch[\"permeability\"])\n",
    "    loss = mse(pred, truth)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Iteration: {i}. Loss: {loss.detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa3d1a4",
   "metadata": {},
   "source": [
    "That’s it! This shows how to use a model from PhysicsNeMo. Most of the models in PhysicsNeMo are highly configurable, allowing you to use them out-of-the-box for different applications. Refer to [PhysicsNeMo Models](https://docs.nvidia.com/physicsnemo/latest/physicsnemo/api_models.html#physicsnemo-models) for a more complete list of available models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89341e8d",
   "metadata": {},
   "source": [
    "### Using Custom Models in PhysicsNeMo\n",
    "\n",
    "PhysicsNeMo provides many pre-built optimized models. However, there might be times when the shipped models might not serve your application. In such cases, you can easily write your own models and have them interact with the other PhysicsNeMo utilities and features. PhysicsNeMo uses PyTorch in the backend, and most PhysicsNeMo models are, at the core, PyTorch models. In this section, you will see how to go from a typical PyTorch model to a PhysicsNeMo model.\n",
    "\n",
    "Let’s get started with the same application of the Darcy problem. Let’s write a simple UNet to solve the problem. A PyTorch model for a UNet can be written as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import physicsnemo\n",
    "from physicsnemo.datapipes.benchmarks.darcy import Darcy2D\n",
    "from physicsnemo.metrics.general.mse import mse\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "\n",
    "        self.dec1 = self.upconv_block(128, 64)\n",
    "        self.dec2 = self.upconv_block(64, 32)\n",
    "        self.final = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "    def upconv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc1(x)\n",
    "        x = self.enc2(x)\n",
    "        x = self.dec1(x)\n",
    "        x = self.dec2(x)\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505a98b",
   "metadata": {},
   "source": [
    "Now, let’s convert this to a PhysicsNeMo model. PhysicsNeMo provides a `Module` class that is designed to be a drop-in replacement for `torch.nn.Module`. Along with that, you need to also pass a `MetaData` that captures the optimizations and other features supported by the model. Using the `Module` subclass allows you to use these optimizations, and other features like checkpointing, from PhysicsNeMo.\n",
    "\n",
    "Thus, converting a PyTorch model to a PhysicsNeMo model is very simple. For the above model, the diff would look something like below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d66352",
   "metadata": {},
   "source": [
    "-    import torch.nn as nn\n",
    "+    from dataclasses import dataclass\n",
    "+    from physicsnemo.models.meta import ModelMetaData\n",
    "+    from physicsnemo.models.module import Module\n",
    "\n",
    "-    class UNet(nn.Module):\n",
    "+    @dataclass\n",
    "+    class MetaData(ModelMetaData):\n",
    "+        name: str = \"UNet\"\n",
    "+        # Optimization\n",
    "+        jit: bool = False\n",
    "+        cuda_graphs: bool = True\n",
    "+        amp_cpu: bool = True\n",
    "+        amp_gpu: bool = True\n",
    "+\n",
    "+    class UNet(Module):\n",
    "         def __init__(self, in_channels=1, out_channels=1):\n",
    "-            super(UNet, self).__init__()\n",
    "+            super(UNet, self).__init__(meta=MetaData())\n",
    "\n",
    "             self.enc1 = self.conv_block(in_channels, 64)\n",
    "             self.enc2 = self.conv_block(64, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d781f",
   "metadata": {},
   "source": [
    "With a few changes like this, you can convert a PyTorch model to a PhysicsNeMo model!\n",
    "\n",
    ">Note\n",
    ">The optimizations are not automatically applied. You are responsible for writing the model with the optimizations supported. However, if the model supports the optimization and the same is captured in the MetaData, then the downstream features will work out-of-the-box.\n",
    "\n",
    ">Note\n",
    ">For utilizing the checkpointing functionality of PhysicsNeMo, the model instantiation arguments must be JSON serializable.\n",
    "\n",
    "You can also use a PhysicsNeMo model as a standard PyTorch model as they are interoperable.\n",
    "\n",
    "Let’s say you don’t want to make changes to the code, but you have a PyTorch model already. You can convert it to a PhysicsNeMo model by using the `physicsnemo.Module.from_torch` method. This is described in detail in [Converting PyTorch Models to PhysicsNeMo Models](https://docs.nvidia.com/physicsnemo/latest/physicsnemo/api/models/modules.html#physicsnemo-models-from-torch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684fb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from physicsnemo.models.meta import ModelMetaData\n",
    "from physicsnemo.models.module import Module\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MdlsUNetMetaData(ModelMetaData):\n",
    "    name: str = \"MdlsUNet\"\n",
    "    # Optimization\n",
    "    jit: bool = False\n",
    "    cuda_graphs: bool = True\n",
    "    amp_cpu: bool = True\n",
    "    amp_gpu: bool = True\n",
    "\n",
    "\n",
    "MdlsUNet = Module.from_torch(UNet, meta=MdlsUNetMetaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91c299",
   "metadata": {},
   "source": [
    "And just like that, you can use your existing PyTorch model as a PhysicsNeMo model. A very similar process can be followed to convert a PhysicsNeMo model to a PhysicsNeMo Sym model so that you can use the constraints and other definitions from the PhysicsNeMo Sym repository. Here, you will use the `Arch` class from PhysicsNeMo Sym that provides utilities and methods to go from tensor data to a dict format which PhysicsNeMo Sym uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "\n",
    "from physicsnemo.sym.key import Key\n",
    "from physicsnemo.sym.models.arch import Arch\n",
    "\n",
    "\n",
    "class MdlsSymUNet(Arch):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_keys=[Key(\"a\")],\n",
    "        output_keys=[Key(\"b\")],\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "    ):\n",
    "        super(MdlsSymUNet, self).__init__(\n",
    "            input_keys=input_keys, output_keys=output_keys\n",
    "        )\n",
    "\n",
    "        self.mdls_model = MdlsUNet(in_channels, out_channels)  # MdlsUNet defined above\n",
    "\n",
    "    def forward(self, dict_tensor: Dict[str, torch.Tensor]):\n",
    "        x = self.concat_input(\n",
    "            dict_tensor,\n",
    "            self.input_key_dict,\n",
    "            detach_dict=None,\n",
    "            dim=1,\n",
    "        )\n",
    "        out = self.mdls_model(x)\n",
    "        return self.split_output(out, self.output_key_dict, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28004ffb",
   "metadata": {},
   "source": [
    "## Optimized Training Workflow\n",
    "\n",
    "Once you have a model defined in the PhysicsNeMo style, you can use the optimizations like AMP, CUDA Graphs, and JIT using the `physicsnemo.utils.StaticCaptureTraining` decorator. This decorator will capture the training step function and optimize it for the specified optimizations.\n",
    "\n",
    ">Note\n",
    ">The `StaticCaptureTraining` decorator is still under development and may be refactored in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655cd65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from physicsnemo.utils import StaticCaptureTraining\n",
    "\n",
    "normaliser = {\n",
    "    \"permeability\": (1.25, 0.75),\n",
    "    \"darcy\": (4.52e-2, 2.79e-2),\n",
    "}\n",
    "dataloader = Darcy2D(\n",
    "    resolution=256, batch_size=8, nr_permeability_freq=5, normaliser=normaliser\n",
    ")\n",
    "model = MdlsUNet().to(\"cuda\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer, lr_lambda=lambda step: 0.85**step\n",
    ")\n",
    "\n",
    "\n",
    "# Create training step function with optimization wrapper\n",
    "# StaticCaptureTraining calls `backward` on the loss and\n",
    "# `optimizer.step()` so you don't have to do that\n",
    "# explicitly.\n",
    "@StaticCaptureTraining(\n",
    "    model=model,\n",
    "    optim=optimizer,\n",
    "    cuda_graph_warmup=11,\n",
    ")\n",
    "def training_step(invar, outvar):\n",
    "    predvar = model(invar)\n",
    "    loss = mse(predvar, outvar)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# run for 20 iterations\n",
    "dataloader = iter(dataloader)\n",
    "for i in range(20):\n",
    "    batch = next(dataloader)\n",
    "    truth = batch[\"darcy\"]\n",
    "    input = batch[\"permeability\"]\n",
    "    loss = training_step(input, truth)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590bf4d",
   "metadata": {},
   "source": [
    "## Distributed Training Workflow\n",
    "\n",
    "PhysicsNeMo has several distributed utilities to simplify the implementation of parallel training and make inference scripts easier by providing a unified way to configure and query parameters associated with the distributed environment.\n",
    "\n",
    "In this example, you will see how to convert your existing workflow to use data parallelism. For a deep-dive on PhysicsNeMo distributed utilities, refer to [PhysicsNeMo Distributed](https://docs.nvidia.com/physicsnemo/latest/user-guide/distributed_training.html#physicsnemo-distributed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcda5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize the DistributedManager. This will automatically\n",
    "    # detect the number of processes the job was launched with and\n",
    "    # set those configuration parameters appropriately.\n",
    "    DistributedManager.initialize()\n",
    "\n",
    "    # Get instance of the DistributedManager\n",
    "    dist = DistributedManager()\n",
    "\n",
    "    normaliser = {\n",
    "        \"permeability\": (1.25, 0.75),\n",
    "        \"darcy\": (4.52e-2, 2.79e-2),\n",
    "    }\n",
    "    dataloader = Darcy2D(\n",
    "        resolution=256, batch_size=64, nr_permeability_freq=5, normaliser=normaliser\n",
    "    )\n",
    "    model = FNO(\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        decoder_layers=1,\n",
    "        decoder_layer_size=32,\n",
    "        dimension=2,\n",
    "        latent_channels=32,\n",
    "        num_fno_layers=4,\n",
    "        num_fno_modes=12,\n",
    "        padding=5,\n",
    "    ).to(dist.device)\n",
    "\n",
    "    # Set up DistributedDataParallel if using more than a single process.\n",
    "    if dist.distributed:\n",
    "        ddps = torch.cuda.Stream()\n",
    "        with torch.cuda.stream(ddps):\n",
    "            model = DistributedDataParallel(\n",
    "                model,\n",
    "                device_ids=[\n",
    "                    dist.local_rank\n",
    "                ],  # Set the device_id to be the local rank of this process on this node\n",
    "                output_device=dist.device,\n",
    "                broadcast_buffers=dist.broadcast_buffers,\n",
    "                find_unused_parameters=dist.find_unused_parameters,\n",
    "            )\n",
    "        torch.cuda.current_stream().wait_stream(ddps)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "        optimizer, lr_lambda=lambda step: 0.85**step\n",
    "    )\n",
    "\n",
    "    # Create training step function with optimization wrapper\n",
    "    # StaticCaptureTraining calls `backward` on the loss and\n",
    "    # `optimizer.step()` so you don't have to do that\n",
    "    # explicitly.\n",
    "    @StaticCaptureTraining(\n",
    "        model=model,\n",
    "        optim=optimizer,\n",
    "        cuda_graph_warmup=11,\n",
    "    )\n",
    "    def training_step(invar, outvar):\n",
    "        predvar = model(invar)\n",
    "        loss = mse(predvar, outvar)\n",
    "        return loss\n",
    "\n",
    "    # run for 20 iterations\n",
    "    dataloader = iter(dataloader)\n",
    "    for i in range(20):\n",
    "        batch = next(dataloader)\n",
    "        truth = batch[\"darcy\"]\n",
    "        input = batch[\"permeability\"]\n",
    "        loss = training_step(input, truth)\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e0053",
   "metadata": {},
   "source": [
    "## Running Inference on Trained Models\n",
    "\n",
    "Running inference on trained models is simple! This is shown by the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    decoder_layers=1,\n",
    "    decoder_layer_size=32,\n",
    "    dimension=2,\n",
    "    latent_channels=32,\n",
    "    num_fno_layers=4,\n",
    "    num_fno_modes=12,\n",
    "    padding=5,\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Save the checkpoint. For demo, we will just save untrained checkpoint,\n",
    "# but in typical workflows is saved after model training.\n",
    "model.save(\"untrained_checkpoint.mdlus\")\n",
    "\n",
    "# Inference code\n",
    "\n",
    "# The parameters to instantitate the model will be loaded from the checkpoint\n",
    "model_inf = physicsnemo.Module.from_checkpoint(\"untrained_checkpoint.mdlus\").to(\"cuda\")\n",
    "\n",
    "# put the model in evaluation mode\n",
    "model_inf.eval()\n",
    "\n",
    "# run inference\n",
    "with torch.inference_mode():\n",
    "    input = torch.ones(8, 1, 256, 256).to(\"cuda\")\n",
    "    output = model_inf(input)\n",
    "    print(output.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
